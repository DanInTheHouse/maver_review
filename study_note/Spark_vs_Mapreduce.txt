# Spark vs. Mapreduce

## Spark (Apache Spark)

- 메모리 기반의 데이터 처리 모델을 사용하여 중간 결과를 디스크에 저장하는 대신 메모리에 유지
    
    → 반복적인 작업이나 반복 알고리즘을 수행할 때 매우 빠른 처리 속도를 제공
    
- Spark는 Java, Scala, Python, 및 R과 같은 다양한 언어에서 사용할 수 있는 API를 제공하기 때문에 고수준의 라이브러리와 내장된 기능들이 제공된다.
- 독립적인 오픈 소스 프로젝트로서, 다양한 데이터 처리 및 머신러닝 라이브러리가 풍부한 생태계를 가짐.

## Mapreduce (Hadoop MapReduce)

- 디스크 기반의 데이터 처리 모델을 사용
- 각 단계에서 데이터를 디스크에 쓰고 읽기 때문에 속도가 느릴 수 있음.
- 기본적으로 Java로 구현되었으며, 개발자가 상대적으로 많은 코드를 작성해야 함
    
    → 복잡성과 개발 시간을 증가시킬 수 있음.
    
- 주로 배치 처리에 적합하며, 반복적인 작업을 처리하는 데에는 불리
- Hadoop과 함께 사용되는 주요 프레임워크 중 하나이며, Hadoop의 하위 프로젝트로 개발

### → MapReduce에 비해 성능, 편의성, 다양한 작업 유형을 처리하는 데 적합하다.